# Virtual Assistant for the Visually Impaired

An advanced AI-powered assistant designed to support visually impaired users through real-time **object detection**, **scene description**, **navigation assistance**, **text reading**, and **voice interaction**. Powered by modern computer vision and speech technologies, the assistant runs on a laptop and provides instant spoken feedback.

---

## ğŸš€ Features

### ğŸ”Š Voice Interaction

* Fully voice-controlled
* Offline speech recognition using **Vosk**
* Natural speech output using **pyttsx3**

### ğŸ‘ï¸ Object Detection

* YOLOv8-n and YOLOv8-s integrated
* Detects objects in real time
* Announces detected objects via speech

### ğŸ§­ Navigation Assistance

* Detects obstacles
* Estimates distance and direction
* Gives real-time navigation warnings

### ğŸ–¼ï¸ Scene Description

* Uses AI to describe surroundings
* Helps users understand environments instantly

### ğŸ“– Text Reader

* Reads documents, signs, boards, and screens
* Uses OCR + TTS for reading aloud

### ğŸ“ Depth Estimation

* Measures object distance
* Alerts user about nearby hazards

---

## ğŸ› ï¸ Tech Stack

* **Python**
* **OpenCV**
* **YOLOv8**
* **Vosk ASR** (offline speech recognition)
* **pyttsx3** (text-to-speech)
* **Flask** (for simple frontend)
* Optional AI API for scene understanding

---

## ğŸ“¦ Project Structure

```
Chat-bot-for-the-Blind/
â”‚â”€â”€ app.py
â”‚â”€â”€ main.py
â”‚â”€â”€ object_detection.py
â”‚â”€â”€ navigation_assistant.py
â”‚â”€â”€ scene_description.py
â”‚â”€â”€ text_reader.py
â”‚â”€â”€ depth_estimation.py
â”‚â”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”‚â”€â”€ vosk-model-small/
â”‚â”€â”€ yolov8n.pt
â”‚â”€â”€ yolov8s.pt
â”‚â”€â”€ requirements.txt
```

---

## â–¶ï¸ How to Run

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Start the assistant

```bash
python3 main.py
```

---

## ğŸ‘¨â€ğŸ’» Author

**Anubhav Chaudhary**

