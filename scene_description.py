"""
scene_description.py
--------------------
Analyzes the scene through the webcam using YOLO object detection,
then uses Groq (LLaMA-3) to generate a natural language summary
for visually impaired users.
"""

import cv2
from ultralytics import YOLO
from groq import Groq
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
GROQ_KEY = os.getenv("GROQ_API_KEY")
client = Groq(api_key=GROQ_KEY)

# Load YOLO model
model = YOLO("yolov8n.pt")

def describe_scene(talk):
    """
    Capture one frame, detect objects, and generate a natural description.
    """
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        talk("Camera not detected.")
        return

    talk("Scanning your surroundings, please wait.")
    ret, frame = cap.read()
    cap.release()

    if not ret:
        talk("I couldn’t capture the image.")
        return

    # Run YOLO detection
    results = model(frame)
    detected_objects = []
    directions = []

    frame_w = frame.shape[1]

    for box in results[0].boxes:
        cls = int(box.cls[0])
        name = model.names[cls]
        conf = float(box.conf[0])
        if conf < 0.5:
            continue

        x1, y1, x2, y2 = box.xyxy[0]
        cx = (x1 + x2) / 2

        if cx < frame_w / 3:
            pos = "left"
        elif cx > frame_w * 2 / 3:
            pos = "right"
        else:
            pos = "center"

        detected_objects.append(name)
        directions.append(pos)

    if not detected_objects:
        talk("I couldn’t detect anything clearly around you.")
        return

    # Build a detection summary
    detections_text = ", ".join([f"{obj} on the {dir}" for obj, dir in zip(detected_objects, directions)])

    # Ask Groq to make it human-friendly
    prompt = f"Describe this scene naturally: I detected {detections_text}."

    try:
        response = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {"role": "system", "content": "You are a helpful assistant for the visually impaired, describing what the camera sees."},
                {"role": "user", "content": prompt},
            ],
        )
        description = response.choices[0].message.content.strip()
        talk(description)
    except Exception as e:
        talk(f"Error generating scene description: {e}")
